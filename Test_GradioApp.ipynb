{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "IMPORTANT: You are using gradio version 4.14.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\queueing.py\", line 495, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\blocks.py\", line 1561, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\blocks.py\", line 1179, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\utils.py\", line 678, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_6196\\1252399418.py\", line 40, in predict\n",
      "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "cv2.error: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "from skimage import feature\n",
    "from PIL import Image\n",
    "from joblib import load\n",
    "import dlib\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = load(\"Model_RF.h5\")\n",
    "\n",
    "# Initialize the dlib face detector\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "emotion_labels = {\n",
    "    0: \"Angry\",\n",
    "    1: \"Fear\",\n",
    "    2: \"Happy\",\n",
    "    3: \"Neutral\",\n",
    "    4: \"Sad\",\n",
    "}\n",
    "\n",
    "def preprocess_image(image):\n",
    "    \"\"\" Convert image to grayscale, resize, and compute HOG features. \"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    resized = cv2.resize(gray, (48, 48))\n",
    "    hog_features = feature.hog(resized, orientations=9, pixels_per_cell=(8, 8),\n",
    "                               cells_per_block=(2, 2), block_norm='L2-Hys',\n",
    "                               visualize=False, transform_sqrt=True)\n",
    "    return hog_features\n",
    "\n",
    "def predict(image):\n",
    "    \"\"\" Detect faces, draw rectangles, preprocess image, and predict emotion. \"\"\"\n",
    "    if isinstance(image, Image.Image):\n",
    "        image = np.array(image)\n",
    "\n",
    "    # Detect faces\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    faces = detector(gray)\n",
    "\n",
    "    if faces:\n",
    "        face = faces[0]  # Focus on the first detected face\n",
    "        x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "        face_region = image[y:y+h, x:x+w]\n",
    "        features = preprocess_image(face_region)\n",
    "        features = features.reshape(1,-1)\n",
    "        x = features.reshape(1,-1)\n",
    "        x_mean = np.mean(x, axis=1, keepdims=True)\n",
    "        x_std = np.std(x, axis=1, keepdims=True)\n",
    "        x_scaled = (x - x_mean) / x_std\n",
    "        print(x_scaled)\n",
    "        prediction = model.predict(x_scaled)\n",
    "        predicted_emotion = emotion_labels[int(prediction[0])]\n",
    "\n",
    "        # Preparing the face image for display\n",
    "        output_face_image = Image.fromarray(face_region)  # Convert NumPy array to PIL Image for Gradio\n",
    "    else:\n",
    "        predicted_emotion = \"No face detected\"\n",
    "        output_face_image = Image.fromarray(image)  # Return the original image if no face detected\n",
    "\n",
    "    return predicted_emotion, output_face_image\n",
    "\n",
    "# Setup Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=\"image\",\n",
    "    outputs=[\"text\", \"image\"],\n",
    "    title=\"Emotion Detection\",\n",
    "    description=\"Upload an image to detect emotions in faces.\",\n",
    ")\n",
    "\n",
    "iface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
